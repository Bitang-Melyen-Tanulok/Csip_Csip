{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bitang-Melyen-Tanulok/Csip_Csip/blob/main/Cross_valid_Train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQrSXadE4xMi",
        "outputId": "97b16529-28c8-4d2d-dc20-76324343608c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Current folder: blrwar1\n",
            "Current folder: categr\n",
            "Current folder: forwag1\n",
            "Current folder: grenig1\n",
            "Current folder: jerbus2\n",
            "Current folder: insowl1\n",
            "Current folder: junmyn1\n",
            "Current folder: lewduc1\n",
            "Current folder: plaflo1\n",
            "Current folder: pursun4\n",
            "Current folder: putbab1\n",
            "Current folder: redspu1\n",
            "Current folder: revbul\n",
            "Current folder: rewlap1\n",
            "Current folder: rufbab3\n",
            "Current folder: rutfly6\n",
            "Current folder: sqtbul1\n",
            "Current folder: vefnut1\n",
            "Current folder: barswa\n",
            "Current folder: rerswa1\n",
            "X shape: (2307, 369, 496, 1)\n",
            "Y shape: (2307,)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from google.colab import drive\n",
        "\n",
        "X = []\n",
        "Y = []\n",
        "drive.mount('/content/drive')\n",
        "path = '/content/drive/MyDrive/DeepLearning'\n",
        "\n",
        "spectrograms_path = os.path.join(path, 'sample_train_spectrograms')  # Path to folder with training data\n",
        "folders = os.listdir(spectrograms_path)\n",
        "\n",
        "for folder in folders:\n",
        "    print(f\"Current folder: {folder}\")\n",
        "    folder_path = os.path.join(spectrograms_path, folder)\n",
        "\n",
        "    # Reading spectrogram files\n",
        "    files = os.listdir(folder_path)\n",
        "\n",
        "    for file in files:\n",
        "        if file.endswith('.png'):  # Only reading PNGs\n",
        "            file_path = os.path.join(folder_path, file)\n",
        "\n",
        "            # Loading image\n",
        "            img = image.load_img(file_path, color_mode='grayscale')\n",
        "            img_array = image.img_to_array(img)  # Converting image into array\n",
        "            X.append(img_array)\n",
        "\n",
        "            # Adding label based on the folder name\n",
        "            Y.append(folder)\n",
        "\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "\n",
        "# Print X and Y shape\n",
        "print(f\"X shape: {X.shape}\")\n",
        "print(f\"Y shape: {Y.shape}\")\n",
        "\n",
        "# Shuffle X and Y the same way\n",
        "permutation = np.random.permutation(len(X))\n",
        "X = X[permutation]\n",
        "Y = Y[permutation]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since this is a multi-class classification task, I am converting labels to one-hot format:"
      ],
      "metadata": {
        "id": "CMxgjW0YKfqY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "#First, the labels need to be converted into numerical values\n",
        "le = LabelEncoder()\n",
        "Y_encoded = le.fit_transform(Y)\n",
        "\n",
        "#Getting number of classes\n",
        "num_classes = len(le.classes_)\n",
        "print(f\"Class number= {num_classes}\")\n",
        "\n",
        "#Converting to one-hot encoding\n",
        "Y_onehot = to_categorical(Y_encoded, num_classes)"
      ],
      "metadata": {
        "id": "8Wr1YIvJXB2e",
        "outputId": "a292705f-1132-4033-aafd-14bcba3dbd61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class number= 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "#Implementing early stopping, since there is no reason for it to learn further when val_loss isn't decreasing\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5, #If it doesn't improve for 5 epochs, it concludes\n",
        "    verbose=1,\n",
        "    restore_best_weights=True\n",
        ")"
      ],
      "metadata": {
        "id": "sDYfYQU49emi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "#Wanting to save the best model, so implementing checkpointing\n",
        "checkpoint = ModelCheckpoint(\n",
        "    'best_model.keras',\n",
        "    monitor='val_loss',\n",
        "    save_best_only=True,\n",
        "    mode='min',\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "_F0hjbhk9guq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "fold_accuracies = []\n",
        "fold_losses = []\n",
        "\n",
        "history_per_fold = []\n",
        "\n",
        "# Start Stratified K-Fold cross-validation\n",
        "fold_number = 1\n",
        "for train_index, valid_index in skf.split(X, Y_encoded):\n",
        "  print(f\"Startung fold: {fold_number}\")\n",
        "\n",
        "  X_train, X_valid = X[train_index], X[valid_index]\n",
        "  Y_train, Y_valid = Y_onehot[train_index], Y_onehot[valid_index]\n",
        "\n",
        "  X_train = X_train / np.max(X_train)\n",
        "  X_valid = X_valid / np.max(X_valid)\n",
        "\n",
        "  model = models.Sequential()\n",
        "  model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(X_train.shape[1], X_train.shape[2], 1)))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(128, activation='relu'))\n",
        "  model.add(layers.Dropout(0.5))\n",
        "  model.add(layers.Dense(num_classes, activation='softmax'))\n",
        "\n",
        "  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  history = model.fit(\n",
        "      X_train, Y_train,\n",
        "      epochs=50,\n",
        "      batch_size=32,\n",
        "      validation_data=(X_valid, Y_valid),\n",
        "      callbacks=[early_stopping, checkpoint],\n",
        "      verbose=1\n",
        "  )\n",
        "\n",
        "  history_per_fold.append(history)\n",
        "\n",
        "  valid_loss, valid_accuracy = model.evaluate(X_valid, Y_valid)\n",
        "\n",
        "  fold_accuracies.append(valid_accuracy)\n",
        "  fold_losses.append(valid_loss)\n",
        "\n",
        "  fold_number += 1\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "GkRTUHa6XL8L",
        "outputId": "40d8b71c-c5d7-48bf-8096-87b5132043d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Startung fold: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12s/step - accuracy: 0.1793 - loss: 3.6410 \n",
            "Epoch 1: val_loss improved from inf to 2.30878, saving model to best_model.keras\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m777s\u001b[0m 13s/step - accuracy: 0.1798 - loss: 3.6272 - val_accuracy: 0.3117 - val_loss: 2.3088\n",
            "Epoch 2/50\n",
            "\u001b[1m27/58\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6:31\u001b[0m 13s/step - accuracy: 0.2116 - loss: 2.4146"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nCross-Validation Results:\")\n",
        "print(f\"Mean Validation Loss: {np.mean(fold_losses)}\")\n",
        "print(f\"Mean Validation Accuracy: {np.mean(fold_accuracies)}\")\n",
        "\n",
        "for i, (loss, accuracy) in enumerate(zip(fold_losses, fold_accuracies), start=1):\n",
        "    print(f\"Fold {i} - Validation Loss: {loss}, Validation Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "id": "IG5spDQxY_e3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot loss and accuracy for each fold\n",
        "for i, history in enumerate(history_per_fold):\n",
        "  plt.figure(figsize=(12, 6))\n",
        "\n",
        "  # Plot accuracy\n",
        "  plt.subplot(1, 2, 1)\n",
        "  plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "  plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "  plt.title(f'Fold {i + 1} Accuracy')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.legend()\n",
        "\n",
        "  # Plot loss\n",
        "  plt.subplot(1, 2, 2)\n",
        "  plt.plot(history.history['loss'], label='Training Loss')\n",
        "  plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "  plt.title(f'Fold {i + 1} Loss')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "pYMtUWV_ETgQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}