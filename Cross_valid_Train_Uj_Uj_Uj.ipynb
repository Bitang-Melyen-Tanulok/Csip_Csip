{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bitang-Melyen-Tanulok/Csip_Csip/blob/main/Cross_valid_Train_Uj_Uj_Uj.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We needed to check if there is any duplication of titles or audio files among the data.\n",
        "\n",
        "If there was, we would then remove them from the database, only keeping the first appearance.\n"
      ],
      "metadata": {
        "id": "g7lCiRbeAAYs"
      }
    },
    {
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive to access files\n",
        "drive.mount('/content/drive')\n",
        "base_path = '/content/drive/MyDrive/DeepLearning'\n",
        "spectrograms_path = os.path.join(base_path, 'ugyanaz?')  # Directory for spectrogram files\n",
        "\n",
        "import hashlib\n",
        "import shutil\n",
        "\n",
        "import os\n",
        "import hashlib\n",
        "\n",
        "X = []\n",
        "Y = []\n",
        "\n",
        "def get_file_hash(file_path):\n",
        "    hash_md5 = hashlib.md5()  # Create an MD5 hash object to store the file's hash value\n",
        "    with open(file_path, \"rb\") as f:\n",
        "        # Read the file in chunks (4KB at a time) and update the hash\n",
        "        for chunk in iter(lambda: f.read(4096), b\"\"):\n",
        "            hash_md5.update(chunk)\n",
        "    return hash_md5.hexdigest()  # Return the final hash value as a hexadecimal string\n",
        "\n",
        "def delete_duplicates_and_log(spectrograms_path):\n",
        "    global X,Y\n",
        "    seen_hashes = set()  # This will store the hashes of files we've already processed\n",
        "    files_to_delete = []  # List to track files that are duplicates and will be deleted\n",
        "    files_to_keep = []  # List to track files that are unique and will be kept\n",
        "\n",
        "    # Walk through the folders in the spectrograms directory\n",
        "    for folder in os.listdir(spectrograms_path):\n",
        "        folder_path = os.path.join(spectrograms_path, folder)\n",
        "\n",
        "        # Loop through the files in the current folder\n",
        "        files = os.listdir(folder_path)\n",
        "        for file in files:\n",
        "            if file.endswith('.png'):  # We're only interested in .png files (spectrograms)\n",
        "                file_path = os.path.join(folder_path, file)\n",
        "\n",
        "                # Generate a hash for the file to compare it with others\n",
        "                file_hash = get_file_hash(file_path)\n",
        "\n",
        "                if file_hash in seen_hashes:\n",
        "                    # If we've already seen this hash, it's a duplicate\n",
        "                    #print(f\"Duplicate file found: {file_path}\")\n",
        "                    files_to_delete.append(file_path)\n",
        "                else:\n",
        "                    # If we haven't seen this hash yet, add it to the seen set and keep it\n",
        "                    seen_hashes.add(file_hash)\n",
        "                    files_to_keep.append(file_path)\n",
        "\n",
        "                    img = image.load_img(file_path, color_mode=\"rgb\")\n",
        "                    img_array = image.img_to_array(img)\n",
        "                    X.append(img_array)\n",
        "                    Y.append(folder)\n",
        "\n",
        "    # Log files that we kept (not duplicates)\n",
        "    '''\n",
        "    print(\"Files kept:\")\n",
        "    for file_path in files_to_keep:\n",
        "        print(f\"   - Keeping file: {file_path}\")\n",
        "    '''\n",
        "\n",
        "    # Log files that we deleted (duplicates)\n",
        "    print(\"\\nFiles deleted:\")\n",
        "    for file_path in files_to_delete:\n",
        "        print(f\"   - Deleting file: {file_path}\")\n",
        "        os.remove(file_path)  # Actually delete the duplicate files\n",
        "\n",
        "    # Convert X and Y to numpy arrays\n",
        "    X = np.array(X)\n",
        "    Y = np.array(Y)\n",
        "\n",
        "    # Shuffle the data\n",
        "    permutation = np.random.permutation(len(X))\n",
        "    X = X[permutation]\n",
        "    Y = Y[permutation]\n",
        "\n",
        "    # Print shapes of the arrays\n",
        "    print(f\"\\nX shape: {X.shape}\")\n",
        "    print(f\"Y shape: {Y.shape}\")\n",
        "\n",
        "    return X, Y\n",
        "\n",
        "X, Y = delete_duplicates_and_log(spectrograms_path)\n",
        "\n"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9wkFCOwSKw7",
        "outputId": "59f2d85a-21c9-4fd5-bb8d-ccbbf3ef5b0c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "\n",
            "Files deleted:\n",
            "\n",
            "X shape: (1769, 128, 313, 3)\n",
            "Y shape: (1769,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since this is a multi-class classification task, I am converting labels to one-hot format:"
      ],
      "metadata": {
        "id": "CMxgjW0YKfqY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "#First, the labels need to be converted into numerical values\n",
        "le = LabelEncoder()\n",
        "Y_encoded = le.fit_transform(Y)\n",
        "\n",
        "#Getting number of classes\n",
        "num_classes = len(le.classes_)\n",
        "print(f\"Class number= {num_classes}\")\n",
        "\n",
        "#Converting to one-hot encoding\n",
        "Y_onehot = to_categorical(Y_encoded, num_classes)"
      ],
      "metadata": {
        "id": "8Wr1YIvJXB2e",
        "outputId": "8eb58e7f-0506-44d3-f040-ee8e63929d95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class number= 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We implemented early stopping, in case the model started overfitting."
      ],
      "metadata": {
        "id": "qbrOkU8JAf8Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "#Implementing early stopping, since there is no reason for it to learn further when val_loss isn't decreasing\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5, #If it doesn't improve for 10 epochs, it concludes\n",
        "    verbose=1,\n",
        "    restore_best_weights=True\n",
        ")"
      ],
      "metadata": {
        "id": "sDYfYQU49emi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint # Importing the missing ModelCheckpoint class\n",
        "\n",
        "#Wanting to save the best model, so implementing checkpointing\n",
        "checkpoint = ModelCheckpoint(\n",
        "    'best_model.keras',\n",
        "    monitor='val_loss',\n",
        "    save_best_only=True,\n",
        "    mode='min',\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "_F0hjbhk9guq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install efficientnet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hk4oZTN7zXcO",
        "outputId": "18868b05-2eb1-4613-c5e8-4921179840cb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting efficientnet\n",
            "  Downloading efficientnet-1.1.1-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting keras-applications<=1.0.8,>=1.0.7 (from efficientnet)\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from efficientnet) (0.25.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.26.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (3.12.1)\n",
            "Requirement already satisfied: scipy>=1.11.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (1.13.1)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (3.4.2)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (11.0.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (2.36.1)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (2024.12.12)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (0.4)\n",
            "Downloading efficientnet-1.1.1-py3-none-any.whl (18 kB)\n",
            "Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: keras-applications, efficientnet\n",
            "Successfully installed efficientnet-1.1.1 keras-applications-1.0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We used efficientNetV2 pretrained model, since most kaggle teams suggested it."
      ],
      "metadata": {
        "id": "1wkKtEyyAycC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from tensorflow.keras.applications import EfficientNetV2B0\n",
        "from tensorflow.keras.applications.efficientnet_v2 import preprocess_input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import mixed_precision\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "import tensorflow as tf\n",
        "\n",
        "# Enable XLA compilation for faster execution\n",
        "# tf.config.optimizer.set_jit(True)\n",
        "\n",
        "# Setting up Stratified K-Fold\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Setting up learning rate sceduler - reduces learning rat if the model stops improving\n",
        "'''\n",
        "lr_scheduler = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.5,\n",
        "    patience=3,\n",
        "    verbose=1,\n",
        "    min_lr=1e-6\n",
        ")\n",
        "'''\n",
        "\n",
        "# Implementing mixed precision training for faster outcomes\n",
        "mixed_precision.set_global_policy('mixed_float16')\n",
        "\n",
        "fold_accuracies = []\n",
        "fold_losses = []\n",
        "history_per_fold = []\n",
        "\n",
        "# Starting K-Fold\n",
        "fold_number = 1\n",
        "for train_index, valid_index in skf.split(X, Y_encoded):\n",
        "    print(f\"Starting fold: {fold_number}\")\n",
        "\n",
        "    # Splitting the data into training and validation sets\n",
        "    X_train, X_valid = X[train_index], X[valid_index]\n",
        "    Y_train, Y_valid = Y_onehot[train_index], Y_onehot[valid_index]\n",
        "\n",
        "    # Normalizing the data\n",
        "    X_train = preprocess_input(X_train)\n",
        "    X_valid = preprocess_input(X_valid)\n",
        "\n",
        "    # Setting the input shape based on the data\n",
        "    input_shape = (X_train.shape[1], X_train.shape[2], X_train.shape[3])\n",
        "\n",
        "    # Loading the pre-trained EfficientNetV2B0 model\n",
        "    base_model = EfficientNetV2B0(\n",
        "        include_top=False,\n",
        "        weights='imagenet',\n",
        "        input_shape=input_shape\n",
        "    )\n",
        "\n",
        "    # Defining a new model\n",
        "    model = models.Sequential()\n",
        "\n",
        "    # Freezing the base model layers if we don't want to update them during training\n",
        "    base_model.trainable = False\n",
        "\n",
        "    # Adding the pre-trained model\n",
        "    model.add(base_model)\n",
        "    model.add(layers.GlobalAveragePooling2D())  # Selecting the best representations\n",
        "\n",
        "    # Adding Dense layers\n",
        "    model.add(layers.Dense(64, activation='relu')) #128\n",
        "    #model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Dropout(0.4))  # Adding Dropout to prevent overfitting\n",
        "    model.add(layers.Dense(num_classes, activation='softmax', dtype='float32'))\n",
        "\n",
        "    # Compiling the model\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Training the model\n",
        "    history = model.fit(\n",
        "        X_train, Y_train,\n",
        "        epochs=20, #30\n",
        "        batch_size=128, # try larger throughput 128, 256, original is 64\n",
        "        validation_data=(X_valid, Y_valid),\n",
        "        callbacks=[early_stopping, checkpoint],\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Fine-tuning\n",
        "    #base_model.trainable = True\n",
        "    for layer in base_model.layers[:-5]: # Freeze all but the top 5 layers\n",
        "      layer.trainable = False\n",
        "\n",
        "    model.compile(optimizer=Adam(1e-5), loss='categorical_crossentropy', metrics=['accuracy']) # low learning rate\n",
        "\n",
        "    fine_tuning_history = model.fit(\n",
        "        X_train, Y_train,\n",
        "        epochs=5,\n",
        "        batch_size=128,\n",
        "        validation_data=(X_valid, Y_valid),\n",
        "        callbacks=[early_stopping, checkpoint],\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Saving the results\n",
        "    history_per_fold.append(history)\n",
        "    valid_loss, valid_accuracy = model.evaluate(X_valid, Y_valid)\n",
        "\n",
        "    fold_accuracies.append(valid_accuracy)\n",
        "    fold_losses.append(valid_loss)\n",
        "\n",
        "    fold_number += 1\n",
        "\n",
        "# Summary of the final model\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "GkRTUHa6XL8L",
        "outputId": "ba385274-c5ed-4cac-9e65-9a75426a9ba6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting fold: 1\n",
            "Epoch 1/20\n",
            "12/12 [==============================] - ETA: 0s - loss: 2.6816 - accuracy: 0.2728 \n",
            "Epoch 1: val_loss did not improve from 1.18156\n",
            "12/12 [==============================] - 152s 12s/step - loss: 2.6816 - accuracy: 0.2728 - val_loss: 2.2102 - val_accuracy: 0.4774\n",
            "Epoch 2/20\n",
            "12/12 [==============================] - ETA: 0s - loss: 1.8609 - accuracy: 0.5223\n",
            "Epoch 2: val_loss did not improve from 1.18156\n",
            "12/12 [==============================] - 137s 12s/step - loss: 1.8609 - accuracy: 0.5223 - val_loss: 1.9476 - val_accuracy: 0.4802\n",
            "Epoch 3/20\n",
            "12/12 [==============================] - ETA: 0s - loss: 1.5774 - accuracy: 0.5887\n",
            "Epoch 3: val_loss did not improve from 1.18156\n",
            "12/12 [==============================] - 138s 12s/step - loss: 1.5774 - accuracy: 0.5887 - val_loss: 1.8142 - val_accuracy: 0.5113\n",
            "Epoch 4/20\n",
            "12/12 [==============================] - ETA: 0s - loss: 1.4127 - accuracy: 0.6424\n",
            "Epoch 4: val_loss did not improve from 1.18156\n",
            "12/12 [==============================] - 137s 12s/step - loss: 1.4127 - accuracy: 0.6424 - val_loss: 1.6766 - val_accuracy: 0.5537\n",
            "Epoch 5/20\n",
            "12/12 [==============================] - ETA: 0s - loss: 1.2926 - accuracy: 0.6572\n",
            "Epoch 5: val_loss did not improve from 1.18156\n",
            "12/12 [==============================] - 137s 12s/step - loss: 1.2926 - accuracy: 0.6572 - val_loss: 1.6167 - val_accuracy: 0.5621\n",
            "Epoch 6/20\n",
            "12/12 [==============================] - ETA: 0s - loss: 1.2095 - accuracy: 0.6678\n",
            "Epoch 6: val_loss did not improve from 1.18156\n",
            "12/12 [==============================] - 138s 12s/step - loss: 1.2095 - accuracy: 0.6678 - val_loss: 1.5366 - val_accuracy: 0.5876\n",
            "Epoch 7/20\n",
            "12/12 [==============================] - ETA: 0s - loss: 1.0943 - accuracy: 0.6996\n",
            "Epoch 7: val_loss did not improve from 1.18156\n",
            "12/12 [==============================] - 136s 11s/step - loss: 1.0943 - accuracy: 0.6996 - val_loss: 1.4465 - val_accuracy: 0.6158\n",
            "Epoch 8/20\n",
            "12/12 [==============================] - ETA: 0s - loss: 1.0127 - accuracy: 0.7244\n",
            "Epoch 8: val_loss did not improve from 1.18156\n",
            "12/12 [==============================] - 137s 12s/step - loss: 1.0127 - accuracy: 0.7244 - val_loss: 1.3683 - val_accuracy: 0.6497\n",
            "Epoch 9/20\n",
            "12/12 [==============================] - ETA: 0s - loss: 1.0248 - accuracy: 0.7166\n",
            "Epoch 9: val_loss did not improve from 1.18156\n",
            "12/12 [==============================] - 137s 12s/step - loss: 1.0248 - accuracy: 0.7166 - val_loss: 1.3222 - val_accuracy: 0.6441\n",
            "Epoch 10/20\n",
            "12/12 [==============================] - ETA: 0s - loss: 0.9747 - accuracy: 0.7449\n",
            "Epoch 10: val_loss did not improve from 1.18156\n",
            "12/12 [==============================] - 136s 11s/step - loss: 0.9747 - accuracy: 0.7449 - val_loss: 1.2820 - val_accuracy: 0.6610\n",
            "Epoch 11/20\n",
            "12/12 [==============================] - ETA: 0s - loss: 0.9050 - accuracy: 0.7505\n",
            "Epoch 11: val_loss did not improve from 1.18156\n",
            "12/12 [==============================] - 137s 12s/step - loss: 0.9050 - accuracy: 0.7505 - val_loss: 1.2267 - val_accuracy: 0.6667\n",
            "Epoch 12/20\n",
            "12/12 [==============================] - ETA: 0s - loss: 0.8554 - accuracy: 0.7682\n",
            "Epoch 12: val_loss did not improve from 1.18156\n",
            "12/12 [==============================] - 137s 12s/step - loss: 0.8554 - accuracy: 0.7682 - val_loss: 1.2543 - val_accuracy: 0.6638\n",
            "Epoch 13/20\n",
            "12/12 [==============================] - ETA: 0s - loss: 0.8043 - accuracy: 0.7746\n",
            "Epoch 13: val_loss did not improve from 1.18156\n",
            "12/12 [==============================] - 137s 12s/step - loss: 0.8043 - accuracy: 0.7746 - val_loss: 1.2139 - val_accuracy: 0.6695\n",
            "Epoch 14/20\n",
            "12/12 [==============================] - ETA: 0s - loss: 0.8353 - accuracy: 0.7597\n",
            "Epoch 14: val_loss did not improve from 1.18156\n",
            "12/12 [==============================] - 136s 11s/step - loss: 0.8353 - accuracy: 0.7597 - val_loss: 1.2123 - val_accuracy: 0.6836\n",
            "Epoch 15/20\n",
            "12/12 [==============================] - ETA: 0s - loss: 0.7743 - accuracy: 0.7936\n",
            "Epoch 15: val_loss improved from 1.18156 to 1.13367, saving model to best_model.keras\n",
            "12/12 [==============================] - 138s 12s/step - loss: 0.7743 - accuracy: 0.7936 - val_loss: 1.1337 - val_accuracy: 0.7175\n",
            "Epoch 16/20\n",
            " 6/12 [==============>...............] - ETA: 1:00 - loss: 0.7283 - accuracy: 0.7995"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nCross-Validation Results:\")\n",
        "print(f\"Mean Validation Loss: {np.mean(fold_losses)}\")\n",
        "print(f\"Mean Validation Accuracy: {np.mean(fold_accuracies)}\")\n",
        "\n",
        "for i, (loss, accuracy) in enumerate(zip(fold_losses, fold_accuracies), start=1):\n",
        "    print(f\"Fold {i} - Validation Loss: {loss}, Validation Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "id": "IG5spDQxY_e3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot loss and accuracy for each fold\n",
        "for i, history in enumerate(history_per_fold):\n",
        "  plt.figure(figsize=(12, 6))\n",
        "\n",
        "  # Plot accuracy\n",
        "  plt.subplot(1, 2, 1)\n",
        "  plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "  plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "  plt.title(f'Fold {i + 1} Accuracy')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.legend()\n",
        "\n",
        "  # Plot loss\n",
        "  plt.subplot(1, 2, 2)\n",
        "  plt.plot(history.history['loss'], label='Training Loss')\n",
        "  plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "  plt.title(f'Fold {i + 1} Loss')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "pYMtUWV_ETgQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}