{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bitang-Melyen-Tanulok/Csip_Csip/blob/main/Train_final2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQrSXadE4xMi",
        "outputId": "ae4e9b11-5e1e-4bc9-b534-8a4ca7f2fa90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Current folder: asbfly\n",
            "Current folder: copbar1\n",
            "Current folder: grenig1\n",
            "Current folder: rerswa1\n",
            "Current folder: marsan\n",
            "Current folder: blrwar1\n",
            "Current folder: jerbus2\n",
            "Current folder: plaflo1\n",
            "Current folder: pursun4\n",
            "Current folder: putbab1\n",
            "Current folder: revbul\n",
            "Current folder: rewlap1\n",
            "Current folder: rufbab3\n",
            "Current folder: sqtbul1\n",
            "Current folder: vefnut1\n",
            "Current folder: barswa\n",
            "Current folder: categr\n",
            "Current folder: forwag1\n",
            "Current folder: brcful1\n",
            "Current folder: ashdro1\n",
            "Current folder: ashpri1\n",
            "Current folder: brnhao1\n",
            "Current folder: ashwoo2\n",
            "Current folder: brnshr\n",
            "Current folder: asikoe2\n",
            "Current folder: brodro1\n",
            "Current folder: brwjac1\n",
            "Current folder: brwowl1\n",
            "Current folder: aspfly1\n",
            "Current folder: aspswi1\n",
            "Current folder: btbeat1\n",
            "Current folder: bwfshr1\n",
            "Current folder: chbeat1\n",
            "Current folder: bcnher\n",
            "Current folder: cohcuc1\n",
            "Current folder: comfla1\n",
            "Current folder: comgre\n",
            "Current folder: bkcbul1\n",
            "Current folder: bkrfla1\n",
            "Current folder: bkskit1\n",
            "Current folder: comior1\n",
            "Current folder: bkwsti\n",
            "Current folder: comkin1\n",
            "Current folder: bladro1\n",
            "Current folder: blakit1\n",
            "Current folder: commoo3\n",
            "Current folder: blhori1\n",
            "Current folder: blnmon1\n",
            "Current folder: commyn\n",
            "Current folder: compea\n",
            "Current folder: comros\n",
            "Current folder: comsan\n",
            "Current folder: comtai1\n",
            "Current folder: crbsun2\n",
            "Current folder: cregos1\n",
            "Current folder: brakit1\n",
            "Current folder: crfbar1\n",
            "Current folder: crseag1\n",
            "Current folder: grewar3\n",
            "Current folder: dafbab1\n",
            "Current folder: eaywag1\n",
            "Current folder: emedov2\n",
            "Current folder: eucdov\n",
            "Current folder: eurbla2\n",
            "Current folder: grnsan\n",
            "Current folder: eurcoo\n",
            "Current folder: grnwar1\n",
            "Current folder: gargan\n",
            "Current folder: grtdro1\n",
            "Current folder: gloibi\n",
            "Current folder: goflea1\n",
            "Current folder: graher1\n",
            "Current folder: gryfra\n",
            "Current folder: grynig2\n",
            "Current folder: grywag\n",
            "Current folder: grbeat1\n",
            "Current folder: grecou1\n",
            "Current folder: greegr\n",
            "Current folder: gybpri1\n",
            "Current folder: grefla1\n",
            "Current folder: gyhcaf1\n",
            "Current folder: grehor1\n",
            "Current folder: grejun2\n",
            "Current folder: heswoo1\n",
            "Current folder: hoopoe\n",
            "Current folder: junbab2\n",
            "Current folder: junowl1\n",
            "Current folder: kenplo1\n",
            "Current folder: houcro1\n",
            "Current folder: houspa\n",
            "Current folder: labcro1\n",
            "Current folder: laudov1\n",
            "Current folder: lblwar1\n",
            "Current folder: lesyel1\n",
            "Current folder: lirplo\n",
            "Current folder: inbrob1\n",
            "Current folder: indpit1\n",
            "Current folder: litegr\n",
            "Current folder: indrob1\n",
            "Current folder: indrol2\n",
            "Current folder: litgre1\n",
            "Current folder: insbab1\n",
            "Current folder: litspi1\n",
            "Current folder: litswi1\n",
            "Current folder: mawthr1\n",
            "Current folder: lobsun2\n",
            "Current folder: moipig1\n",
            "Current folder: maghor2\n",
            "Current folder: malpar1\n",
            "Current folder: nutman\n",
            "Current folder: maltro1\n",
            "Current folder: orihob2\n",
            "Current folder: oripip1\n",
            "Current folder: rewbul\n",
            "Current folder: pabflo1\n",
            "Current folder: piebus1\n",
            "Current folder: rocpig\n",
            "Current folder: piekin1\n",
            "Current folder: rorpar\n",
            "Current folder: placuc3\n",
            "Current folder: plapri1\n",
            "Current folder: plhpar1\n",
            "Current folder: pomgrp2\n",
            "Current folder: purher1\n",
            "Current folder: pursun3\n",
            "Current folder: rossta2\n",
            "Current folder: purswa3\n",
            "Current folder: ruftre2\n",
            "Current folder: rufwoo2\n",
            "Current folder: sbeowl1\n",
            "Current folder: vehpar1\n",
            "Current folder: scamin3\n",
            "Current folder: shikra1\n",
            "Current folder: wemhar1\n",
            "Current folder: smamin1\n",
            "Current folder: sohmyn1\n",
            "Current folder: spepic1\n",
            "Current folder: spodov\n",
            "Current folder: whbbul2\n",
            "Current folder: spoowl1\n",
            "Current folder: whbsho3\n",
            "Current folder: stbkin1\n",
            "Current folder: whbtre1\n",
            "Current folder: sttwoo1\n",
            "Current folder: whbwag1\n",
            "Current folder: thbwar1\n",
            "Current folder: whbwat1\n",
            "Current folder: whbwoo2\n",
            "Current folder: whcbar1\n",
            "Current folder: whiter2\n",
            "Current folder: woosan\n",
            "Current folder: yebbab1\n",
            "Current folder: yebbul3\n",
            "Current folder: zitcis1\n",
            "Current folder: asiope1\n",
            "Current folder: blaeag1\n",
            "Current folder: bncwoo3\n",
            "Current folder: darter2\n",
            "Current folder: integr\n",
            "Current folder: inpher1\n",
            "Current folder: insowl1\n",
            "Current folder: kerlau2\n",
            "Current folder: lewduc1\n",
            "Current folder: nilfly2\n",
            "Current folder: niwpig1\n",
            "Current folder: rutfly6\n",
            "Current folder: whtkin2\n",
            "Current folder: wbbfly1\n",
            "Current folder: redspu1\n",
            "\n",
            "X shape: (18228, 128, 313, 3)\n",
            "Y shape: (18228,)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from PIL import Image\n",
        "from google.colab import drive\n",
        "\n",
        "X = []\n",
        "Y = []\n",
        "drive.mount('/content/drive')\n",
        "path = '/content/drive/MyDrive/DeepLearning'\n",
        "spectrograms_path = os.path.join(path, 'train_spectrograms')  # Adott mappa elérési útvonala\n",
        "folders = os.listdir(spectrograms_path)\n",
        "\n",
        "for folder in folders:\n",
        "    print(f\"Current folder: {folder}\")\n",
        "    folder_path = os.path.join(spectrograms_path, folder)  # Mappa útvonal\n",
        "\n",
        "    # Fájlok bejárása a mappában\n",
        "    files = os.listdir(folder_path)\n",
        "\n",
        "    for file in files:\n",
        "        if file.endswith('.png'):  # Csak PNG fájlokat olvasunk be\n",
        "            file_path = os.path.join(folder_path, file)\n",
        "\n",
        "            # Kép betöltése\n",
        "            img = image.load_img(file_path, color_mode='rgb')\n",
        "            img_array = image.img_to_array(img)  # Kép tömbbé alakítása\n",
        "            X.append(img_array)\n",
        "            Y.append(folder)\n",
        "\n",
        "\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "\n",
        "print(f\"\\nX shape: {X.shape}\")\n",
        "print(f\"Y shape: {Y.shape}\")\n",
        "\n",
        "#shuffle X and Y the same way\n",
        "permutation = np.random.permutation(len(X))\n",
        "X = X[permutation]\n",
        "Y = Y[permutation]\n",
        "\n",
        "test_split = 0.1\n",
        "valid_split = 0.1\n",
        "\n",
        "nb_samples = len(X)\n",
        "valid_start_idx = int(nb_samples*(1-valid_split-test_split))\n",
        "test_start_idx = int(nb_samples*(1-test_split))\n",
        "\n",
        "X_train = X[:valid_start_idx]\n",
        "Y_train = Y[:valid_start_idx]\n",
        "X_valid = X[valid_start_idx:test_start_idx]\n",
        "Y_valid = Y[valid_start_idx:test_start_idx]\n",
        "X_test = X[test_start_idx:]\n",
        "Y_test = Y[test_start_idx:]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save X any Y to '/content/drive/MyDrive/DeepLearning/X' and '/content/drive/MyDrive/DeepLearning/Y'\n",
        "np.save('/content/drive/MyDrive/DeepLearning/X.npy', X)\n",
        "np.save('/content/drive/MyDrive/DeepLearning/Y.npy', Y)"
      ],
      "metadata": {
        "id": "LtyhzGM1IpOI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load X and Y\n",
        "X = np.load('/content/drive/MyDrive/DeepLearning/X.npy')\n",
        "Y = np.load('/content/drive/MyDrive/DeepLearning/Y.npy')\n",
        "\n",
        "X_train = X[:valid_start_idx]\n",
        "Y_train = Y[:valid_start_idx]\n",
        "X_valid = X[valid_start_idx:test_start_idx]\n",
        "Y_valid = Y[valid_start_idx:test_start_idx]\n",
        "X_test = X[test_start_idx:]\n",
        "Y_test = Y[test_start_idx:]"
      ],
      "metadata": {
        "id": "AeSDuETyRDnz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "#Since this is a multi-class classification task, I am converting labels to one-hot format:\n",
        "\n",
        "#First, the labels need to be converted into numerical values\n",
        "le = LabelEncoder()\n",
        "Y_train_encoded = le.fit_transform(Y_train)\n",
        "Y_valid_encoded = le.transform(Y_valid)\n",
        "Y_test_encoded = le.transform(Y_test)\n",
        "\n",
        "#Getting number of classes\n",
        "num_classes = len(le.classes_)\n",
        "print(f\"Class number= {num_classes}\")\n",
        "\n",
        "# Converting to one-hot encoding\n",
        "Y_train= to_categorical(Y_train_encoded, num_classes)\n",
        "Y_valid = to_categorical(Y_valid_encoded, num_classes)\n",
        "Y_test = to_categorical(Y_test_encoded, num_classes)"
      ],
      "metadata": {
        "id": "8Wr1YIvJXB2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66403de4-4c32-4e60-b156-bbc880b6c3cd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class number= 169\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "#Implementing early stopping, since there is no reason for it to learn further when val_loss isn't decreasing\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5, #If it doesn't improve for 10 epochs, it concludes\n",
        "    verbose=1,\n",
        "    restore_best_weights=True\n",
        ")"
      ],
      "metadata": {
        "id": "FUAtgZ4iuF9d"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint # Importing the missing ModelCheckpoint class\n",
        "\n",
        "checkpoint_dir = '/content/drive/MyDrive/DeepLearning/checkpoints2'\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "checkpoint_train_path = os.path.join(checkpoint_dir, 'model_train_{epoch:02d}_{val_loss:.4f}.keras')\n",
        "checkpoint_finetune_path = os.path.join(checkpoint_dir, 'model_finetune_{epoch:02d}_{val_loss:.4f}.keras')\n",
        "\n",
        "#Saving the latest model at each epoch, so that if colab collapses, we don't have to start from zero\n",
        "checkpoint_train = ModelCheckpoint(\n",
        "    checkpoint_train_path,\n",
        "    monitor='val_loss',\n",
        "    save_best_only=False,\n",
        "    save_weights_only=False,\n",
        "    save_freq='epoch',\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "checkpoint_finetune = ModelCheckpoint(\n",
        "    checkpoint_finetune_path,\n",
        "    monitor='val_loss',\n",
        "    save_best_only=False,\n",
        "    save_weights_only=False,\n",
        "    save_freq='epoch',\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "2ykyRUDhuG5P"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def return_latest_checkpoint_path(checkpoint_dir, fold_prefix):\n",
        "    model_files = os.listdir(checkpoint_dir)\n",
        "    # Filter files that match the fold_prefix\n",
        "    model_files = [f for f in model_files if f.startswith(fold_prefix)]\n",
        "    if not model_files:\n",
        "        print(\"No checkpoint found for fold.\")\n",
        "        return None, 0\n",
        "\n",
        "    # Extract epoch numbers using regex\n",
        "    epoch_numbers = []\n",
        "    for f in model_files:\n",
        "        match = re.search(r'_(\\d+)', f)  # Extract the number after fold prefix and before '_val_loss'\n",
        "        if match:\n",
        "            epoch_numbers.append((int(match.group(1)), f))\n",
        "\n",
        "    # Get the latest file by epoch number\n",
        "    latest_epoch, latest_file = max(epoch_numbers, key=lambda x: x[0])\n",
        "    latest_model_path = os.path.join(checkpoint_dir, latest_file)\n",
        "\n",
        "    return latest_model_path, latest_epoch"
      ],
      "metadata": {
        "id": "ZeMm1FEluNQv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install efficientnet"
      ],
      "metadata": {
        "id": "IiGrBwwOuQiO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afa5d681-d409-41af-b1da-3fc67cb9c781"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting efficientnet\n",
            "  Downloading efficientnet-1.1.1-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting keras-applications<=1.0.8,>=1.0.7 (from efficientnet)\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from efficientnet) (0.25.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.26.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (3.12.1)\n",
            "Requirement already satisfied: scipy>=1.11.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (1.13.1)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (3.4.2)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (11.0.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (2.36.1)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (2024.12.12)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (0.4)\n",
            "Downloading efficientnet-1.1.1-py3-none-any.whl (18 kB)\n",
            "Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: keras-applications, efficientnet\n",
            "Successfully installed efficientnet-1.1.1 keras-applications-1.0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from tensorflow.keras.applications import EfficientNetV2B0\n",
        "from tensorflow.keras.applications.efficientnet_v2 import preprocess_input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import mixed_precision\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Implementing mixed precision training for faster outcomes\n",
        "mixed_precision.set_global_policy('mixed_float16')\n",
        "\n",
        "# Normalizing the data to fit EfficientNetV2B0\n",
        "X_train = preprocess_input(X_train)\n",
        "X_valid = preprocess_input(X_valid)\n",
        "\n",
        "# Setting the input shape based on the data\n",
        "input_shape = (X_train.shape[1], X_train.shape[2], X_train.shape[3])\n",
        "\n",
        "# Loading the pre-trained EfficientNetV2B0 model\n",
        "base_model = EfficientNetV2B0(\n",
        "    include_top=False,\n",
        "    weights='imagenet',\n",
        "    input_shape=input_shape\n",
        ")\n",
        "\n",
        "# Defining a new model\n",
        "model = models.Sequential()\n",
        "\n",
        "# Freezing the base model layers if we don't want to update them during training\n",
        "base_model.trainable = False\n",
        "\n",
        "# Adding the pre-trained model\n",
        "model.add(base_model)\n",
        "model.add(layers.GlobalAveragePooling2D())  # Selecting the best representations\n",
        "# Adding additional layers\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Dropout(0.5))  # Adding Dropout to prevent overfitting\n",
        "model.add(layers.Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Loading saved model with the latest epoch froim 'model_train_{epoch:02d}_{val_loss:.4f}.keras'\n",
        "latest_checkpoint_path, initial_epoch = return_latest_checkpoint_path(checkpoint_dir, 'model_train')\n",
        "if latest_checkpoint_path:\n",
        "    model = load_model(latest_checkpoint_path)\n",
        "    print(\"Resumed training from the latest checkpoint.\")\n",
        "else:\n",
        "    initial_epoch = 0\n",
        "    print(\"Starting training from scratch.\")\n",
        "\n",
        "# Compiling the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Training the model\n",
        "history = model.fit(\n",
        "    X_train, Y_train,\n",
        "    epochs=20,\n",
        "    initial_epoch=initial_epoch,\n",
        "    batch_size=256, # try larger throughput 128, 256, original is 64\n",
        "    validation_data=(X_valid, Y_valid),\n",
        "    callbacks=[early_stopping, checkpoint_train],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Fine-tuning the last 10 layers\n",
        "base_model.trainable = False\n",
        "for layer in base_model.layers[-10:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "# Loading saved model with the latest epoch froim 'model_train_{epoch:02d}_{val_loss:.4f}.keras'\n",
        "latest_checkpoint_path, initial_epoch = return_latest_checkpoint_path(checkpoint_dir, 'model_finetune')\n",
        "if latest_checkpoint_path:\n",
        "    model = load_model(latest_checkpoint_path)\n",
        "    print(\"Resumed fine-tuning from the latest checkpoint.\")\n",
        "else:\n",
        "    initial_epoch = 0\n",
        "    print(\"Starting fine-tuning from scratch.\")\n",
        "\n",
        "model.compile(optimizer=Adam(1e-5), loss='categorical_crossentropy', metrics=['accuracy']) # low learning rate\n",
        "\n",
        "fine_tuning_history = model.fit(\n",
        "    X_train, Y_train,\n",
        "    epochs=5,\n",
        "    initial_epoch=initial_epoch,\n",
        "    batch_size=256,\n",
        "    validation_data=(X_valid, Y_valid),\n",
        "    callbacks=[early_stopping, checkpoint_finetune],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Saving the results\n",
        "final_model_path = os.path.join(checkpoint_dir, 'final_model.keras')\n",
        "model.save(final_model_path)\n",
        "\n",
        "# Summary of the final model\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "X5otFkcSuURW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7478de2f-2d66-4c3c-cfee-4d15be8e5d4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resumed training from the latest checkpoint.\n",
            "Epoch 3/20\n",
            "40/57 [====================>.........] - ETA: 5:44 - loss: 3.2056 - accuracy: 0.2969"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Diplaying accuracy and loss on separate diagrams\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Plot accuracy\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title(f'Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# Plot loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title(f'Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FdDH9g7BZCXP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}