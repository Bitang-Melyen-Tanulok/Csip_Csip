{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bitang-Melyen-Tanulok/Csip_Csip/blob/main/Cross_valid_Train_Uj_Uj_Uj_mentessel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We needed to check if there is any duplication of titles or audio files among the data.\n",
        "\n",
        "If there was, we would then remove them from the database, only keeping the first appearance.\n"
      ],
      "metadata": {
        "id": "g7lCiRbeAAYs"
      }
    },
    {
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive to access files\n",
        "drive.mount('/content/drive')\n",
        "base_path = '/content/drive/MyDrive/DeepLearning'\n",
        "spectrograms_path = os.path.join(base_path, 'ugyanaz?')  # Directory for spectrogram files\n",
        "\n",
        "import hashlib\n",
        "import shutil\n",
        "\n",
        "import os\n",
        "import hashlib\n",
        "\n",
        "X = []\n",
        "Y = []\n",
        "\n",
        "def get_file_hash(file_path):\n",
        "    hash_md5 = hashlib.md5()  # Create an MD5 hash object to store the file's hash value\n",
        "    with open(file_path, \"rb\") as f:\n",
        "        # Read the file in chunks (4KB at a time) and update the hash\n",
        "        for chunk in iter(lambda: f.read(4096), b\"\"):\n",
        "            hash_md5.update(chunk)\n",
        "    return hash_md5.hexdigest()  # Return the final hash value as a hexadecimal string\n",
        "\n",
        "def delete_duplicates_and_log(spectrograms_path):\n",
        "    global X,Y\n",
        "    seen_hashes = set()  # This will store the hashes of files we've already processed\n",
        "    files_to_delete = []  # List to track files that are duplicates and will be deleted\n",
        "    files_to_keep = []  # List to track files that are unique and will be kept\n",
        "\n",
        "    # Walk through the folders in the spectrograms directory\n",
        "    for folder in os.listdir(spectrograms_path):\n",
        "        folder_path = os.path.join(spectrograms_path, folder)\n",
        "\n",
        "        # Loop through the files in the current folder\n",
        "        files = os.listdir(folder_path)\n",
        "        for file in files:\n",
        "            if file.endswith('.png'):  # We're only interested in .png files (spectrograms)\n",
        "                file_path = os.path.join(folder_path, file)\n",
        "\n",
        "                # Generate a hash for the file to compare it with others\n",
        "                file_hash = get_file_hash(file_path)\n",
        "\n",
        "                if file_hash in seen_hashes:\n",
        "                    # If we've already seen this hash, it's a duplicate\n",
        "                    #print(f\"Duplicate file found: {file_path}\")\n",
        "                    files_to_delete.append(file_path)\n",
        "                else:\n",
        "                    # If we haven't seen this hash yet, add it to the seen set and keep it\n",
        "                    seen_hashes.add(file_hash)\n",
        "                    files_to_keep.append(file_path)\n",
        "\n",
        "                    img = image.load_img(file_path, color_mode=\"rgb\")\n",
        "                    img_array = image.img_to_array(img)\n",
        "                    X.append(img_array)\n",
        "                    Y.append(folder)\n",
        "\n",
        "    # Log files that we kept (not duplicates)\n",
        "    '''\n",
        "    print(\"Files kept:\")\n",
        "    for file_path in files_to_keep:\n",
        "        print(f\"   - Keeping file: {file_path}\")\n",
        "    '''\n",
        "\n",
        "    # Log files that we deleted (duplicates)\n",
        "    print(\"\\nFiles deleted:\")\n",
        "    for file_path in files_to_delete:\n",
        "        print(f\"   - Deleting file: {file_path}\")\n",
        "        os.remove(file_path)  # Actually delete the duplicate files\n",
        "\n",
        "    # Convert X and Y to numpy arrays\n",
        "    X = np.array(X)\n",
        "    Y = np.array(Y)\n",
        "\n",
        "    # Shuffle the data\n",
        "    permutation = np.random.permutation(len(X))\n",
        "    X = X[permutation]\n",
        "    Y = Y[permutation]\n",
        "\n",
        "    # Print shapes of the arrays\n",
        "    print(f\"\\nX shape: {X.shape}\")\n",
        "    print(f\"Y shape: {Y.shape}\")\n",
        "\n",
        "    return X, Y\n",
        "\n",
        "X, Y = delete_duplicates_and_log(spectrograms_path)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9wkFCOwSKw7",
        "outputId": "2d49f26b-99f5-4b87-9fad-8e74894e1212"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "\n",
            "Files deleted:\n",
            "\n",
            "X shape: (1769, 128, 313, 3)\n",
            "Y shape: (1769,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since this is a multi-class classification task, I am converting labels to one-hot format:"
      ],
      "metadata": {
        "id": "CMxgjW0YKfqY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "#First, the labels need to be converted into numerical values\n",
        "le = LabelEncoder()\n",
        "Y_encoded = le.fit_transform(Y)\n",
        "\n",
        "#Getting number of classes\n",
        "num_classes = len(le.classes_)\n",
        "print(f\"Class number= {num_classes}\")\n",
        "\n",
        "#Converting to one-hot encoding\n",
        "Y_onehot = to_categorical(Y_encoded, num_classes)"
      ],
      "metadata": {
        "id": "8Wr1YIvJXB2e",
        "outputId": "f1fc38f2-8aa8-4697-ed36-22eb769f3e86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class number= 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We implemented early stopping, in case the model started overfitting."
      ],
      "metadata": {
        "id": "qbrOkU8JAf8Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "#Implementing early stopping, since there is no reason for it to learn further when val_loss isn't decreasing\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5, #If it doesn't improve for 10 epochs, it concludes\n",
        "    verbose=1,\n",
        "    restore_best_weights=True\n",
        ")"
      ],
      "metadata": {
        "id": "sDYfYQU49emi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint # Importing the missing ModelCheckpoint class\n",
        "\n",
        "checkpoint_dir = '/content/drive/MyDrive/DeepLearning/checkpoints_sample'\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "checkpoint_path = os.path.join(checkpoint_dir, 'model_epoch_{epoch:02d}_val_loss_{val_loss:.4f}.keras')\n",
        "\n",
        "#Saving the latest model at each epoch, so that if colab collapses, we don't have to start from zero\n",
        "checkpoint = ModelCheckpoint(\n",
        "    checkpoint_path,\n",
        "    monitor='val_loss',\n",
        "    save_best_only=False,\n",
        "    save_weights_only=False,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "_F0hjbhk9guq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install efficientnet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hk4oZTN7zXcO",
        "outputId": "2a4cc8d1-d60b-4dd6-a81e-85d9f00e623f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting efficientnet\n",
            "  Downloading efficientnet-1.1.1-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting keras-applications<=1.0.8,>=1.0.7 (from efficientnet)\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from efficientnet) (0.25.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.26.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (3.12.1)\n",
            "Requirement already satisfied: scipy>=1.11.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (1.13.1)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (3.4.2)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (11.0.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (2.36.1)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (2024.12.12)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (0.4)\n",
            "Downloading efficientnet-1.1.1-py3-none-any.whl (18 kB)\n",
            "Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: keras-applications, efficientnet\n",
            "Successfully installed efficientnet-1.1.1 keras-applications-1.0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We used efficientNetV2 pretrained model, since most kaggle teams suggested it."
      ],
      "metadata": {
        "id": "1wkKtEyyAycC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from tensorflow.keras.applications import EfficientNetV2B0\n",
        "from tensorflow.keras.applications.efficientnet_v2 import preprocess_input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import mixed_precision\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "import tensorflow as tf\n",
        "\n",
        "# Enable XLA compilation for faster execution\n",
        "# tf.config.optimizer.set_jit(True)\n",
        "\n",
        "# Setting up Stratified K-Fold\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Implementing mixed precision training for faster outcomes\n",
        "mixed_precision.set_global_policy('mixed_float16')\n",
        "\n",
        "# Setting up learning rate sceduler - reduces learning rat if the model stops improving\n",
        "# lr_scheduler = ReduceLROnPlateau(\n",
        "#     monitor='val_loss',\n",
        "#     factor=0.5,\n",
        "#     patience=3,\n",
        "#     verbose=1,\n",
        "#     min_lr=1e-6\n",
        "# )\n",
        "\n",
        "# load checkpoint\n",
        "latest_checkpoint = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "if latest_checkpoint:\n",
        "    print(f\"Loading latest checkpoint: {latest_checkpoint}\")\n",
        "    model=tf.keras.models.load_model(latest_checkpoint)\n",
        "else:\n",
        "    print(\"No checkpoint found.\")\n",
        "\n",
        "fold_accuracies = []\n",
        "fold_losses = []\n",
        "history_per_fold = []\n",
        "\n",
        "# Starting K-Fold\n",
        "fold_number = 1\n",
        "for train_index, valid_index in skf.split(X, Y_encoded):\n",
        "    print(f\"Starting fold: {fold_number}\")\n",
        "\n",
        "    # Splitting the data into training and validation sets\n",
        "    X_train, X_valid = X[train_index], X[valid_index]\n",
        "    Y_train, Y_valid = Y_onehot[train_index], Y_onehot[valid_index]\n",
        "\n",
        "    # Normalizing the data\n",
        "    X_train = preprocess_input(X_train)\n",
        "    X_valid = preprocess_input(X_valid)\n",
        "\n",
        "    # Setting the input shape based on the data\n",
        "    input_shape = (X_train.shape[1], X_train.shape[2], X_train.shape[3])\n",
        "\n",
        "    # Loading the pre-trained EfficientNetV2B0 model\n",
        "    base_model = EfficientNetV2B0(\n",
        "        include_top=False,\n",
        "        weights='imagenet',\n",
        "        input_shape=input_shape\n",
        "    )\n",
        "\n",
        "    # Defining a new model\n",
        "    model = models.Sequential()\n",
        "\n",
        "    # Freezing the base model layers if we don't want to update them during training\n",
        "    base_model.trainable = False\n",
        "\n",
        "    # Adding the pre-trained model\n",
        "    model.add(base_model)\n",
        "    model.add(layers.GlobalAveragePooling2D())  # Selecting the best representations\n",
        "\n",
        "    # Adding Dense layers\n",
        "    model.add(layers.Dense(128, activation='relu')) #128\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Dropout(0.4))  # Adding Dropout to prevent overfitting\n",
        "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    # Compiling the model\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    latest_checkpoint = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "    if latest_checkpoint:\n",
        "        print(f\"Loading latest checkpoint: {latest_checkpoint}\")\n",
        "        model.load_weights(latest_checkpoint)\n",
        "\n",
        "    # Training the model\n",
        "    history = model.fit(\n",
        "        X_train, Y_train,\n",
        "        epochs=30, #20?\n",
        "        batch_size=128, # try larger throughput 128, 256, original is 64\n",
        "        validation_data=(X_valid, Y_valid),\n",
        "        callbacks=[early_stopping, checkpoint],\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Fine-tuning the last 10 layers\n",
        "    base_model.trainable = False\n",
        "    for layer in base_model.layers[-10:]:\n",
        "        layer.trainable = True\n",
        "\n",
        "    model.compile(optimizer=Adam(1e-5), loss='categorical_crossentropy', metrics=['accuracy']) # low learning rate\n",
        "\n",
        "    fine_tuning_history = model.fit(\n",
        "        X_train, Y_train,\n",
        "        epochs=10,\n",
        "        batch_size=128,\n",
        "        validation_data=(X_valid, Y_valid),\n",
        "        callbacks=[early_stopping, checkpoint],\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Saving the results\n",
        "    final_model_path = os.path.join(checkpoint_dir, f'final_model_fold_{fold_numbar}.keras')\n",
        "    model.save(final_model_path)\n",
        "\n",
        "    valid_loss, valid_accuracy = model.evaluate(X_valid, Y_valid)\n",
        "\n",
        "    fold_accuracies.append(valid_accuracy)\n",
        "    fold_losses.append(valid_loss)\n",
        "    history_per_fold.append(history)\n",
        "\n",
        "    fold_number += 1\n",
        "\n",
        "# Summary of the final model\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "GkRTUHa6XL8L",
        "outputId": "1ffb29e2-e1d8-4ea5-8553-7d13157babea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-8bfd3e9b1067>\u001b[0m in \u001b[0;36m<cell line: 38>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# Starting K-Fold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mfold_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mskf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_encoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Starting fold: {fold_number}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nCross-Validation Results:\")\n",
        "print(f\"Mean Validation Loss: {np.mean(fold_losses)}\")\n",
        "print(f\"Mean Validation Accuracy: {np.mean(fold_accuracies)}\")\n",
        "\n",
        "for i, (loss, accuracy) in enumerate(zip(fold_losses, fold_accuracies), start=1):\n",
        "    print(f\"Fold {i} - Validation Loss: {loss}, Validation Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "id": "IG5spDQxY_e3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot loss and accuracy for each fold\n",
        "for i, history in enumerate(history_per_fold):\n",
        "  plt.figure(figsize=(12, 6))\n",
        "\n",
        "  # Plot accuracy\n",
        "  plt.subplot(1, 2, 1)\n",
        "  plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "  plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "  plt.title(f'Fold {i + 1} Accuracy')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.legend()\n",
        "\n",
        "  # Plot loss\n",
        "  plt.subplot(1, 2, 2)\n",
        "  plt.plot(history.history['loss'], label='Training Loss')\n",
        "  plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "  plt.title(f'Fold {i + 1} Loss')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "pYMtUWV_ETgQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}