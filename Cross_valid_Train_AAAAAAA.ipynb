{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bitang-Melyen-Tanulok/Csip_Csip/blob/main/Cross_valid_Train_AAAAAAA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy\n",
        "!pip install matplotlib\n",
        "!pip install tensorflow\n",
        "!pip install sklearn\n",
        "!pip install google"
      ],
      "metadata": {
        "id": "7ulMldOtxsPn",
        "outputId": "6c7eb169-1f4f-4f3c-f3ce-ec500fe641e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in d:\\programok\\miniforge3\\lib\\site-packages (2.2.1)\n",
            "Collecting matplotlib\n",
            "  Downloading matplotlib-3.10.0-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib)\n",
            "  Downloading contourpy-1.3.1-cp312-cp312-win_amd64.whl.metadata (5.4 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib)\n",
            "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib)\n",
            "  Downloading fonttools-4.55.3-cp312-cp312-win_amd64.whl.metadata (168 kB)\n",
            "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
            "  Downloading kiwisolver-1.4.8-cp312-cp312-win_amd64.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: numpy>=1.23 in d:\\programok\\miniforge3\\lib\\site-packages (from matplotlib) (2.2.1)\n",
            "Requirement already satisfied: packaging>=20.0 in d:\\programok\\miniforge3\\lib\\site-packages (from matplotlib) (24.2)\n",
            "Collecting pillow>=8 (from matplotlib)\n",
            "  Downloading pillow-11.1.0-cp312-cp312-win_amd64.whl.metadata (9.3 kB)\n",
            "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
            "  Downloading pyparsing-3.2.1-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in d:\\programok\\miniforge3\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in d:\\programok\\miniforge3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Downloading matplotlib-3.10.0-cp312-cp312-win_amd64.whl (8.0 MB)\n",
            "   ---------------------------------------- 0.0/8.0 MB ? eta -:--:--\n",
            "   ------ --------------------------------- 1.3/8.0 MB 7.4 MB/s eta 0:00:01\n",
            "   -------------- ------------------------- 2.9/8.0 MB 7.3 MB/s eta 0:00:01\n",
            "   ---------------------- ----------------- 4.5/8.0 MB 7.5 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 6.3/8.0 MB 7.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------  7.9/8.0 MB 7.7 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 8.0/8.0 MB 7.5 MB/s eta 0:00:00\n",
            "Downloading contourpy-1.3.1-cp312-cp312-win_amd64.whl (220 kB)\n",
            "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Downloading fonttools-4.55.3-cp312-cp312-win_amd64.whl (2.2 MB)\n",
            "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
            "   ---------------------------- ----------- 1.6/2.2 MB 9.3 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 2.2/2.2 MB 8.3 MB/s eta 0:00:00\n",
            "Downloading kiwisolver-1.4.8-cp312-cp312-win_amd64.whl (71 kB)\n",
            "Downloading pillow-11.1.0-cp312-cp312-win_amd64.whl (2.6 MB)\n",
            "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
            "   --------------------------- ------------ 1.8/2.6 MB 8.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 2.6/2.6 MB 8.4 MB/s eta 0:00:00\n",
            "Downloading pyparsing-3.2.1-py3-none-any.whl (107 kB)\n",
            "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
            "Successfully installed contourpy-1.3.1 cycler-0.12.1 fonttools-4.55.3 kiwisolver-1.4.8 matplotlib-3.10.0 pillow-11.1.0 pyparsing-3.2.1\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.18.0-cp312-cp312-win_amd64.whl.metadata (3.3 kB)\n",
            "Collecting tensorflow-intel==2.18.0 (from tensorflow)\n",
            "  Downloading tensorflow_intel-2.18.0-cp312-cp312-win_amd64.whl.metadata (4.9 kB)\n",
            "Collecting absl-py>=1.0.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
            "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
            "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting flatbuffers>=24.3.25 (from tensorflow-intel==2.18.0->tensorflow)\n",
            "  Downloading flatbuffers-24.12.23-py2.py3-none-any.whl.metadata (876 bytes)\n",
            "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-intel==2.18.0->tensorflow)\n",
            "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.18.0->tensorflow)\n",
            "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
            "Collecting libclang>=13.0.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
            "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
            "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.18.0->tensorflow)\n",
            "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: packaging in d:\\programok\\miniforge3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.2)\n",
            "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 (from tensorflow-intel==2.18.0->tensorflow)\n",
            "  Downloading protobuf-5.29.2-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in d:\\programok\\miniforge3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in d:\\programok\\miniforge3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (75.6.0)\n",
            "Requirement already satisfied: six>=1.12.0 in d:\\programok\\miniforge3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.17.0)\n",
            "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
            "  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in d:\\programok\\miniforge3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.2)\n",
            "Collecting wrapt>=1.11.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
            "  Downloading wrapt-1.17.0-cp312-cp312-win_amd64.whl.metadata (6.5 kB)\n",
            "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.18.0->tensorflow)\n",
            "  Downloading grpcio-1.68.1-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
            "Collecting tensorboard<2.19,>=2.18 (from tensorflow-intel==2.18.0->tensorflow)\n",
            "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting keras>=3.5.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
            "  Downloading keras-3.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting numpy<2.1.0,>=1.26.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
            "  Downloading numpy-2.0.2-cp312-cp312-win_amd64.whl.metadata (59 kB)\n",
            "Collecting h5py>=3.11.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
            "  Downloading h5py-3.12.1-cp312-cp312-win_amd64.whl.metadata (2.5 kB)\n",
            "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
            "  Downloading ml_dtypes-0.4.1-cp312-cp312-win_amd64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in d:\\programok\\miniforge3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.45.1)\n",
            "Collecting rich (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
            "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting namex (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
            "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
            "Collecting optree (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
            "  Downloading optree-0.13.1-cp312-cp312-win_amd64.whl.metadata (48 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\programok\\miniforge3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in d:\\programok\\miniforge3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\programok\\miniforge3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in d:\\programok\\miniforge3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.8.30)\n",
            "Collecting markdown>=2.6.8 (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow)\n",
            "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow)\n",
            "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting werkzeug>=1.0.1 (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow)\n",
            "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in d:\\programok\\miniforge3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.2)\n",
            "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
            "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\programok\\miniforge3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
            "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Downloading tensorflow-2.18.0-cp312-cp312-win_amd64.whl (7.5 kB)\n",
            "Downloading tensorflow_intel-2.18.0-cp312-cp312-win_amd64.whl (390.3 MB)\n",
            "   ---------------------------------------- 0.0/390.3 MB ? eta -:--:--\n",
            "    --------------------------------------- 5.2/390.3 MB 31.7 MB/s eta 0:00:13\n",
            "    --------------------------------------- 9.4/390.3 MB 36.7 MB/s eta 0:00:11\n",
            "    --------------------------------------- 9.4/390.3 MB 36.7 MB/s eta 0:00:11\n",
            "    --------------------------------------- 9.4/390.3 MB 36.7 MB/s eta 0:00:11\n",
            "    --------------------------------------- 9.4/390.3 MB 36.7 MB/s eta 0:00:11\n",
            "    --------------------------------------- 9.4/390.3 MB 36.7 MB/s eta 0:00:11\n",
            "    --------------------------------------- 9.4/390.3 MB 36.7 MB/s eta 0:00:11\n",
            "    --------------------------------------- 9.4/390.3 MB 36.7 MB/s eta 0:00:11\n",
            "    --------------------------------------- 9.4/390.3 MB 36.7 MB/s eta 0:00:11\n",
            "    --------------------------------------- 9.4/390.3 MB 36.7 MB/s eta 0:00:11\n",
            "    --------------------------------------- 9.4/390.3 MB 36.7 MB/s eta 0:00:11\n",
            "    --------------------------------------- 9.4/390.3 MB 36.7 MB/s eta 0:00:11\n",
            "    --------------------------------------- 9.4/390.3 MB 36.7 MB/s eta 0:00:11\n",
            "    --------------------------------------- 9.4/390.3 MB 36.7 MB/s eta 0:00:11\n",
            "    --------------------------------------- 9.4/390.3 MB 36.7 MB/s eta 0:00:11\n",
            "    --------------------------------------- 9.4/390.3 MB 36.7 MB/s eta 0:00:11\n",
            "    --------------------------------------- 9.4/390.3 MB 36.7 MB/s eta 0:00:11\n",
            "    --------------------------------------- 9.4/390.3 MB 36.7 MB/s eta 0:00:11\n",
            "    --------------------------------------- 9.4/390.3 MB 36.7 MB/s eta 0:00:11\n",
            "    --------------------------------------- 9.4/390.3 MB 36.7 MB/s eta 0:00:11\n",
            "    --------------------------------------- 9.4/390.3 MB 36.7 MB/s eta 0:00:11\n",
            "    --------------------------------------- 9.4/390.3 MB 36.7 MB/s eta 0:00:11\n",
            "    --------------------------------------- 9.4/390.3 MB 36.7 MB/s eta 0:00:11\n",
            "    --------------------------------------- 9.4/390.3 MB 36.7 MB/s eta 0:00:11\n",
            "    --------------------------------------- 9.4/390.3 MB 36.7 MB/s eta 0:00:11\n",
            "    --------------------------------------- 9.4/390.3 MB 36.7 MB/s eta 0:00:11\n",
            "    --------------------------------------- 9.4/390.3 MB 36.7 MB/s eta 0:00:11\n",
            "    --------------------------------------- 9.4/390.3 MB 36.7 MB/s eta 0:00:11\n",
            "    --------------------------------------- 9.4/390.3 MB 36.7 MB/s eta 0:00:11\n",
            "    --------------------------------------- 9.4/390.3 MB 36.7 MB/s eta 0:00:11\n",
            "   - -------------------------------------- 11.5/390.3 MB 1.8 MB/s eta 0:03:35\n",
            "   - -------------------------------------- 11.5/390.3 MB 1.8 MB/s eta 0:03:35\n",
            "   - -------------------------------------- 15.5/390.3 MB 2.2 MB/s eta 0:02:50\n",
            "   -- ------------------------------------- 24.9/390.3 MB 3.5 MB/s eta 0:01:45\n",
            "   --- ------------------------------------ 33.6/390.3 MB 4.6 MB/s eta 0:01:19\n",
            "   ---- ----------------------------------- 42.5/390.3 MB 5.6 MB/s eta 0:01:02\n",
            "   ----- ---------------------------------- 52.2/390.3 MB 6.7 MB/s eta 0:00:51\n",
            "   ------ --------------------------------- 60.8/390.3 MB 7.6 MB/s eta 0:00:44\n",
            "   ------- -------------------------------- 70.3/390.3 MB 8.6 MB/s eta 0:00:38\n",
            "   -------- ------------------------------- 79.4/390.3 MB 9.5 MB/s eta 0:00:33\n",
            "   --------- ------------------------------ 87.8/390.3 MB 10.2 MB/s eta 0:00:30\n",
            "   --------- ------------------------------ 97.5/390.3 MB 11.1 MB/s eta 0:00:27\n",
            "   ---------- ---------------------------- 105.9/390.3 MB 11.7 MB/s eta 0:00:25\n",
            "   ----------- --------------------------- 114.3/390.3 MB 12.4 MB/s eta 0:00:23\n",
            "   ------------ -------------------------- 124.0/390.3 MB 13.1 MB/s eta 0:00:21\n",
            "   ------------- ------------------------- 132.9/390.3 MB 13.8 MB/s eta 0:00:19\n",
            "   -------------- ------------------------ 142.3/390.3 MB 14.4 MB/s eta 0:00:18\n",
            "   --------------- ----------------------- 151.5/390.3 MB 15.0 MB/s eta 0:00:16\n",
            "   --------------- ----------------------- 159.9/390.3 MB 15.5 MB/s eta 0:00:15\n",
            "   ---------------- ---------------------- 166.2/390.3 MB 15.8 MB/s eta 0:00:15\n",
            "   ----------------- --------------------- 170.9/390.3 MB 15.9 MB/s eta 0:00:14\n",
            "   ------------------ -------------------- 180.4/390.3 MB 16.5 MB/s eta 0:00:13\n",
            "   ------------------ -------------------- 190.1/390.3 MB 17.0 MB/s eta 0:00:12\n",
            "   ------------------- ------------------- 199.8/390.3 MB 17.6 MB/s eta 0:00:11\n",
            "   -------------------- ------------------ 208.9/390.3 MB 18.0 MB/s eta 0:00:11\n",
            "   --------------------- ----------------- 216.0/390.3 MB 18.3 MB/s eta 0:00:10\n",
            "   ---------------------- ---------------- 224.4/390.3 MB 18.7 MB/s eta 0:00:09\n",
            "   ----------------------- --------------- 232.5/390.3 MB 19.1 MB/s eta 0:00:09\n",
            "   ----------------------- --------------- 239.6/390.3 MB 19.3 MB/s eta 0:00:08\n",
            "   ------------------------ -------------- 248.8/390.3 MB 19.7 MB/s eta 0:00:08\n",
            "   ------------------------- ------------- 258.2/390.3 MB 20.1 MB/s eta 0:00:07\n",
            "   -------------------------- ------------ 267.9/390.3 MB 20.3 MB/s eta 0:00:07\n",
            "   --------------------------- ----------- 277.9/390.3 MB 41.1 MB/s eta 0:00:03\n",
            "   ---------------------------- ---------- 287.3/390.3 MB 41.2 MB/s eta 0:00:03\n",
            "   ----------------------------- --------- 296.7/390.3 MB 41.2 MB/s eta 0:00:03\n",
            "   ------------------------------ -------- 306.7/390.3 MB 41.3 MB/s eta 0:00:03\n",
            "   ------------------------------- ------- 316.4/390.3 MB 41.2 MB/s eta 0:00:02\n",
            "   -------------------------------- ------ 325.6/390.3 MB 41.3 MB/s eta 0:00:02\n",
            "   --------------------------------- ----- 335.0/390.3 MB 41.4 MB/s eta 0:00:02\n",
            "   ---------------------------------- ---- 342.4/390.3 MB 41.3 MB/s eta 0:00:02\n",
            "   ---------------------------------- ---- 345.2/390.3 MB 40.3 MB/s eta 0:00:02\n",
            "   ---------------------------------- ---- 348.4/390.3 MB 39.5 MB/s eta 0:00:02\n",
            "   ----------------------------------- --- 356.5/390.3 MB 39.2 MB/s eta 0:00:01\n",
            "   ------------------------------------ -- 364.9/390.3 MB 39.3 MB/s eta 0:00:01\n",
            "   ------------------------------------- - 374.3/390.3 MB 39.3 MB/s eta 0:00:01\n",
            "   --------------------------------------  384.0/390.3 MB 39.3 MB/s eta 0:00:01\n",
            "   --------------------------------------  390.1/390.3 MB 39.3 MB/s eta 0:00:01\n",
            "   --------------------------------------  390.1/390.3 MB 39.3 MB/s eta 0:00:01\n",
            "   --------------------------------------  390.1/390.3 MB 39.3 MB/s eta 0:00:01\n",
            "   --------------------------------------- 390.3/390.3 MB 36.6 MB/s eta 0:00:00\n",
            "Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
            "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Downloading flatbuffers-24.12.23-py2.py3-none-any.whl (30 kB)\n",
            "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
            "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "Downloading grpcio-1.68.1-cp312-cp312-win_amd64.whl (4.4 MB)\n",
            "   ---------------------------------------- 0.0/4.4 MB ? eta -:--:--\n",
            "   ---------------------------------------- 4.4/4.4 MB 37.9 MB/s eta 0:00:00\n",
            "Downloading h5py-3.12.1-cp312-cp312-win_amd64.whl (3.0 MB)\n",
            "   ---------------------------------------- 0.0/3.0 MB ? eta -:--:--\n",
            "   ---------------------------------------- 3.0/3.0 MB 29.4 MB/s eta 0:00:00\n",
            "Downloading keras-3.7.0-py3-none-any.whl (1.2 MB)\n",
            "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
            "   ---------------------------------------- 1.2/1.2 MB 30.2 MB/s eta 0:00:00\n",
            "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
            "   ---------------------------------------- 0.0/26.4 MB ? eta -:--:--\n",
            "   -------------- ------------------------- 9.4/26.4 MB 45.2 MB/s eta 0:00:01\n",
            "   ---------------------------- ----------- 18.6/26.4 MB 45.2 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 25.7/26.4 MB 39.7 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 26.4/26.4 MB 37.2 MB/s eta 0:00:00\n",
            "Downloading ml_dtypes-0.4.1-cp312-cp312-win_amd64.whl (127 kB)\n",
            "Downloading numpy-2.0.2-cp312-cp312-win_amd64.whl (15.6 MB)\n",
            "   ---------------------------------------- 0.0/15.6 MB ? eta -:--:--\n",
            "   -------------------- ------------------- 7.9/15.6 MB 37.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 15.6/15.6 MB 39.3 MB/s eta 0:00:00\n",
            "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
            "Downloading protobuf-5.29.2-cp310-abi3-win_amd64.whl (434 kB)\n",
            "Downloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
            "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
            "   ---------------------------------------- 5.5/5.5 MB 41.9 MB/s eta 0:00:00\n",
            "Downloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading wrapt-1.17.0-cp312-cp312-win_amd64.whl (38 kB)\n",
            "Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
            "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
            "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
            "Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
            "Downloading optree-0.13.1-cp312-cp312-win_amd64.whl (292 kB)\n",
            "Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
            "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Installing collected packages: namex, libclang, flatbuffers, wrapt, werkzeug, termcolor, tensorboard-data-server, protobuf, optree, opt-einsum, numpy, mdurl, markdown, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, ml-dtypes, markdown-it-py, h5py, rich, keras, tensorflow-intel, tensorflow\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.2.1\n",
            "    Uninstalling numpy-2.2.1:\n",
            "      Successfully uninstalled numpy-2.2.1\n",
            "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.12.23 gast-0.6.0 google-pasta-0.2.0 grpcio-1.68.1 h5py-3.12.1 keras-3.7.0 libclang-18.1.1 markdown-3.7 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.4.1 namex-0.0.8 numpy-2.0.2 opt-einsum-3.4.0 optree-0.13.1 protobuf-5.29.2 rich-13.9.4 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorflow-2.18.0 tensorflow-intel-2.18.0 termcolor-2.5.0 werkzeug-3.1.3 wrapt-1.17.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  WARNING: Failed to remove contents in a temporary directory 'D:\\Programok\\miniforge3\\Lib\\site-packages\\~umpy.libs'.\n",
            "  You can safely remove it manually.\n",
            "  WARNING: Failed to remove contents in a temporary directory 'D:\\Programok\\miniforge3\\Lib\\site-packages\\~umpy'.\n",
            "  You can safely remove it manually.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.post12.tar.gz (2.6 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'error'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  error: subprocess-exited-with-error\n",
            "  \n",
            "  python setup.py egg_info did not run successfully.\n",
            "  exit code: 1\n",
            "  \n",
            "  [15 lines of output]\n",
            "  The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
            "  rather than 'sklearn' for pip commands.\n",
            "  \n",
            "  Here is how to fix this error in the main use cases:\n",
            "  - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
            "  - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
            "    (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
            "  - if the 'sklearn' package is used by one of your dependencies,\n",
            "    it would be great if you take some time to track which package uses\n",
            "    'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
            "  - as a last resort, set the environment variable\n",
            "    SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
            "  \n",
            "  More information is available at\n",
            "  https://github.com/scikit-learn/sklearn-pypi-package\n",
            "  [end of output]\n",
            "  \n",
            "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "error: metadata-generation-failed\n",
            "\n",
            "Encountered error while generating package metadata.\n",
            "\n",
            "See above for output.\n",
            "\n",
            "note: This is an issue with the package mentioned above, not pip.\n",
            "hint: See above for details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting google\n",
            "  Downloading google-3.0.0-py2.py3-none-any.whl.metadata (627 bytes)\n",
            "Requirement already satisfied: beautifulsoup4 in d:\\programok\\miniforge3\\lib\\site-packages (from google) (4.12.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in d:\\programok\\miniforge3\\lib\\site-packages (from beautifulsoup4->google) (2.6)\n",
            "Downloading google-3.0.0-py2.py3-none-any.whl (45 kB)\n",
            "Installing collected packages: google\n",
            "Successfully installed google-3.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sklearn"
      ],
      "metadata": {
        "id": "1Aqu7sgU0lKY",
        "outputId": "a1e0d9f7-88f2-4dee-9be3-f87f3183ccdd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sklearn\n",
            "  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'error'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  error: subprocess-exited-with-error\n",
            "  \n",
            "  python setup.py egg_info did not run successfully.\n",
            "  exit code: 1\n",
            "  \n",
            "  [15 lines of output]\n",
            "  The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
            "  rather than 'sklearn' for pip commands.\n",
            "  \n",
            "  Here is how to fix this error in the main use cases:\n",
            "  - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
            "  - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
            "    (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
            "  - if the 'sklearn' package is used by one of your dependencies,\n",
            "    it would be great if you take some time to track which package uses\n",
            "    'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
            "  - as a last resort, set the environment variable\n",
            "    SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
            "  \n",
            "  More information is available at\n",
            "  https://github.com/scikit-learn/sklearn-pypi-package\n",
            "  [end of output]\n",
            "  \n",
            "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "error: metadata-generation-failed\n",
            "\n",
            "Encountered error while generating package metadata.\n",
            "\n",
            "See above for output.\n",
            "\n",
            "note: This is an issue with the package mentioned above, not pip.\n",
            "hint: See above for details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "id": "tQrSXadE4xMi",
        "outputId": "33cd5afe-5d06-44b4-c08c-899dac67d916"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'sklearn'",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[14], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m image\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[0;32m      8\u001b[0m X \u001b[38;5;241m=\u001b[39m []\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from google.colab import drive\n",
        "\n",
        "X = []\n",
        "Y = []\n",
        "drive.mount('/content/drive')\n",
        "path = '/content/drive/MyDrive/DeepLearning'\n",
        "\n",
        "spectrograms_path = os.path.join(path, 'ugyanaz?')  # Path to folder with training data\n",
        "folders = os.listdir(spectrograms_path)\n",
        "\n",
        "for folder in folders:\n",
        "    print(f\"Current folder: {folder}\")\n",
        "    folder_path = os.path.join(spectrograms_path, folder)\n",
        "\n",
        "    # Reading spectrogram files\n",
        "    files = os.listdir(folder_path)\n",
        "\n",
        "    for file in files:\n",
        "        if file.endswith('.png'):  # Only reading PNGs\n",
        "            file_path = os.path.join(folder_path, file)\n",
        "\n",
        "            # Loading image\n",
        "            img = image.load_img(file_path, color_mode='grayscale')\n",
        "            img_array = image.img_to_array(img)  # Converting image into array\n",
        "            X.append(img_array)\n",
        "\n",
        "            # Adding label based on the folder name\n",
        "            Y.append(folder)\n",
        "\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "\n",
        "# Print X and Y shape\n",
        "print(f\"X shape: {X.shape}\")\n",
        "print(f\"Y shape: {Y.shape}\")\n",
        "\n",
        "# Shuffle X and Y the same way\n",
        "permutation = np.random.permutation(len(X))\n",
        "X = X[permutation]\n",
        "Y = Y[permutation]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since this is a multi-class classification task, I am converting labels to one-hot format:"
      ],
      "metadata": {
        "id": "CMxgjW0YKfqY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "#First, the labels need to be converted into numerical values\n",
        "le = LabelEncoder()\n",
        "Y_encoded = le.fit_transform(Y)\n",
        "\n",
        "#Getting number of classes\n",
        "num_classes = len(le.classes_)\n",
        "print(f\"Class number= {num_classes}\")\n",
        "\n",
        "#Converting to one-hot encoding\n",
        "Y_onehot = to_categorical(Y_encoded, num_classes)"
      ],
      "metadata": {
        "id": "8Wr1YIvJXB2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "#Implementing early stopping, since there is no reason for it to learn further when val_loss isn't decreasing\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5, #If it doesn't improve for 5 epochs, it concludes\n",
        "    verbose=1,\n",
        "    restore_best_weights=True\n",
        ")"
      ],
      "metadata": {
        "id": "sDYfYQU49emi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "#Wanting to save the best model, so implementing checkpointing\n",
        "checkpoint = ModelCheckpoint(\n",
        "    'best_model.keras',\n",
        "    monitor='val_loss',\n",
        "    save_best_only=True,\n",
        "    mode='min',\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "_F0hjbhk9guq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "fold_accuracies = []\n",
        "fold_losses = []\n",
        "\n",
        "history_per_fold = []\n",
        "\n",
        "# Start Stratified K-Fold cross-validation\n",
        "fold_number = 1\n",
        "for train_index, valid_index in skf.split(X, Y_encoded):\n",
        "  print(f\"Startung fold: {fold_number}\")\n",
        "\n",
        "  X_train, X_valid = X[train_index], X[valid_index]\n",
        "  Y_train, Y_valid = Y_onehot[train_index], Y_onehot[valid_index]\n",
        "\n",
        "  X_train = X_train / np.max(X_train)\n",
        "  X_valid = X_valid / np.max(X_valid)\n",
        "\n",
        "  model = models.Sequential()\n",
        "  model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(X_train.shape[1], X_train.shape[2], 1)))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(128, activation='relu'))\n",
        "  model.add(layers.Dropout(0.5))\n",
        "  model.add(layers.Dense(num_classes, activation='softmax'))\n",
        "\n",
        "  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  history = model.fit(\n",
        "      X_train, Y_train,\n",
        "      epochs=50,\n",
        "      batch_size=32,\n",
        "      validation_data=(X_valid, Y_valid),\n",
        "      callbacks=[early_stopping, checkpoint],\n",
        "      verbose=1\n",
        "  )\n",
        "\n",
        "  history_per_fold.append(history)\n",
        "\n",
        "  valid_loss, valid_accuracy = model.evaluate(X_valid, Y_valid)\n",
        "\n",
        "  fold_accuracies.append(valid_accuracy)\n",
        "  fold_losses.append(valid_loss)\n",
        "\n",
        "  fold_number += 1\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "GkRTUHa6XL8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nCross-Validation Results:\")\n",
        "print(f\"Mean Validation Loss: {np.mean(fold_losses)}\")\n",
        "print(f\"Mean Validation Accuracy: {np.mean(fold_accuracies)}\")\n",
        "\n",
        "for i, (loss, accuracy) in enumerate(zip(fold_losses, fold_accuracies), start=1):\n",
        "    print(f\"Fold {i} - Validation Loss: {loss}, Validation Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "id": "IG5spDQxY_e3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot loss and accuracy for each fold\n",
        "for i, history in enumerate(history_per_fold):\n",
        "  plt.figure(figsize=(12, 6))\n",
        "\n",
        "  # Plot accuracy\n",
        "  plt.subplot(1, 2, 1)\n",
        "  plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "  plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "  plt.title(f'Fold {i + 1} Accuracy')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.legend()\n",
        "\n",
        "  # Plot loss\n",
        "  plt.subplot(1, 2, 2)\n",
        "  plt.plot(history.history['loss'], label='Training Loss')\n",
        "  plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "  plt.title(f'Fold {i + 1} Loss')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "pYMtUWV_ETgQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}